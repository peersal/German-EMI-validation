{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e42f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T14:09:23.539595Z",
     "iopub.status.busy": "2024-06-23T14:09:23.539183Z",
     "iopub.status.idle": "2024-06-23T14:09:50.602804Z",
     "shell.execute_reply": "2024-06-23T14:09:50.601889Z"
    },
    "papermill": {
     "duration": 27.071487,
     "end_time": "2024-06-23T14:09:50.605519",
     "exception": false,
     "start_time": "2024-06-23T14:09:23.534032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordfreq\r\n",
      "  Downloading wordfreq-3.1.1-py3-none-any.whl.metadata (27 kB)\r\n",
      "Collecting ftfy>=6.1 (from wordfreq)\r\n",
      "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: langcodes>=3.0 in /opt/conda/lib/python3.10/site-packages (from wordfreq) (3.4.0)\r\n",
      "Collecting locate<2.0.0,>=1.1.1 (from wordfreq)\r\n",
      "  Downloading locate-1.1.1-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from wordfreq) (1.0.7)\r\n",
      "Requirement already satisfied: regex>=2023.10.3 in /opt/conda/lib/python3.10/site-packages (from wordfreq) (2023.12.25)\r\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy>=6.1->wordfreq) (0.2.13)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes>=3.0->wordfreq) (1.2.0)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes>=3.0->wordfreq) (1.1.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from marisa-trie>=0.7.7->language-data>=1.2->langcodes>=3.0->wordfreq) (69.0.3)\r\n",
      "Downloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading locate-1.1.1-py3-none-any.whl (5.4 kB)\r\n",
      "Installing collected packages: locate, ftfy, wordfreq\r\n",
      "Successfully installed ftfy-6.2.0 locate-1.1.1 wordfreq-3.1.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wordfreq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.stats import zscore\n",
    "from wordfreq import top_n_list\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450d040e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T14:09:50.621424Z",
     "iopub.status.busy": "2024-06-23T14:09:50.620577Z",
     "iopub.status.idle": "2024-06-23T14:11:09.283217Z",
     "shell.execute_reply": "2024-06-23T14:11:09.281949Z"
    },
    "papermill": {
     "duration": 78.673377,
     "end_time": "2024-06-23T14:11:09.285876",
     "exception": false,
     "start_time": "2024-06-23T14:09:50.612499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: Load the model and find similar words\n",
    "model = Word2Vec.load(\"/kaggle/input/word2vec-new/word2vec_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4effbfa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T14:11:09.302051Z",
     "iopub.status.busy": "2024-06-23T14:11:09.301603Z",
     "iopub.status.idle": "2024-06-23T14:12:38.781524Z",
     "shell.execute_reply": "2024-06-23T14:12:38.779848Z"
    },
    "papermill": {
     "duration": 89.490986,
     "end_time": "2024-06-23T14:12:38.784362",
     "exception": false,
     "start_time": "2024-06-23T14:11:09.293376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/1599769541.py:2: DtypeWarning: Columns (7,8,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/kaggle/input/german-parliament/speeches_all.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_dicts = pd.read_csv(\"/kaggle/input/dictionary2/PRODEMINFO_German_keywords.csv\")\n",
    "df = pd.read_csv(\"/kaggle/input/german-parliament/speeches_all.csv\")\n",
    "df.rename(columns={\"sentence\": \"speechContent\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e79acff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T14:12:38.799801Z",
     "iopub.status.busy": "2024-06-23T14:12:38.799408Z",
     "iopub.status.idle": "2024-06-23T14:12:38.805589Z",
     "shell.execute_reply": "2024-06-23T14:12:38.804337Z"
    },
    "papermill": {
     "duration": 0.016517,
     "end_time": "2024-06-23T14:12:38.807758",
     "exception": false,
     "start_time": "2024-06-23T14:12:38.791241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your evidence and intuition keywords\n",
    "evidence_keywords = df_dicts[\"evidence\"].tolist()\n",
    "intuition_keywords = df_dicts.iloc[0:38][\"intuition\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5527060e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T14:12:38.823880Z",
     "iopub.status.busy": "2024-06-23T14:12:38.823192Z",
     "iopub.status.idle": "2024-06-23T14:12:38.878818Z",
     "shell.execute_reply": "2024-06-23T14:12:38.877687Z"
    },
    "papermill": {
     "duration": 0.066669,
     "end_time": "2024-06-23T14:12:38.881336",
     "exception": false,
     "start_time": "2024-06-23T14:12:38.814667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure to use tqdm.pandas() to add the progress_apply method\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "# Function to preprocess the text data\n",
    "def preprocess(df, length_threshold=10, chunk_text=False, min_chunk_length=50, max_chunk_length=150):\n",
    "    \n",
    "    def remove_special_characters(text):\n",
    "        # Define a regular expression pattern that matches all non-alphanumeric characters except for ä, ö, ü\n",
    "        pattern = r'[^a-zA-Z0-9äöüÄÖÜ\\s]'\n",
    "        # Replace special characters with an empty string\n",
    "        clean_text = re.sub(pattern, '', text)\n",
    "        return clean_text\n",
    "\n",
    "    # Clean text\n",
    "    df['speechContent'] = df[\"speechContent\"].astype(str)\n",
    "    df[\"speechContent\"].replace(to_replace=r\"\\.\\.+\", value=\" \", regex=True, inplace=True)\n",
    "    df[\"speechContent\"].replace(to_replace=r\"\\-\\-+\", value=\" \", regex=True, inplace=True)\n",
    "    df[\"speechContent\"].replace(to_replace=r\"__+\", value=\" \", regex=True, inplace=True)\n",
    "    df[\"speechContent\"].replace(to_replace=r\"\\*\\*+\", value=\" \", regex=True, inplace=True)\n",
    "    df[\"speechContent\"].replace(to_replace=r\"\\s+\", value=\" \", regex=True, inplace=True)\n",
    "    df[\"speechContent\"] = df[\"speechContent\"].progress_apply(remove_special_characters)\n",
    "    \n",
    "    df['length'] = df.speechContent.progress_apply(lambda x: len(x.split()))\n",
    "    \n",
    "    \n",
    "    df = df[df['length'] > length_threshold]\n",
    "    \n",
    "    print(f\"Average Speech length: {[df['length'].mean()]}\")\n",
    "\n",
    "    # Optional: chunk text into smaller parts\n",
    "    if chunk_text:\n",
    "        def chunk_by_length(x):\n",
    "            words = x.split()\n",
    "            if len(words) > max_chunk_length:\n",
    "                chunks = [words[i:i+max_chunk_length] for i in range(0, len(words), max_chunk_length)]\n",
    "                last_chunk_length = len(chunks[-1])\n",
    "                if len(chunks) > 1 and last_chunk_length < min_chunk_length:\n",
    "                    chunks[-2] = chunks[-2] + chunks[-1]\n",
    "                    del chunks[-1]\n",
    "                chunked = [\" \".join(chunk) for chunk in chunks]\n",
    "            else:\n",
    "                chunked = [\" \".join(words)]\n",
    "            return chunked \n",
    "\n",
    "        df['speechContent'] = df.speechContent.progress_apply(chunk_by_length)\n",
    "        df = df.explode(\"speechContent\", ignore_index=True)    \n",
    "        df = df.drop_duplicates(subset=['speechContent']+['id'])\n",
    "        df['chunk_length'] = df.speechContent.progress_apply(lambda x: len(x.split()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Compute average word vectors for documents\n",
    "def document_vector(model, tokens):\n",
    "    vector = np.mean([model.wv[token] for token in tokens if token in model.wv], axis=0)\n",
    "    return vector\n",
    "\n",
    "\n",
    "def compute_similarity_scores(df, model, evidence_keywords, intuition_keywords):\n",
    "    evidence_embeddings = np.mean([model.wv[word] for word in evidence_keywords if word in model.wv], axis=0).reshape(1, -1)\n",
    "    intuition_embeddings = np.mean([model.wv[word] for word in intuition_keywords if word in model.wv], axis=0).reshape(1, -1)\n",
    "    \n",
    "    tqdm.pandas()\n",
    "    \n",
    "    df['document_vector'] = df['speechContent'].progress_apply(lambda tokens: document_vector(model, tokens).reshape(1, -1))\n",
    "    df['document_vector'] = df['document_vector'].apply(lambda vec: vec.reshape(1, -1))\n",
    "    \n",
    "    df['evidence_similarity'] = df['document_vector'].apply(lambda vec: cosine_similarity(vec, evidence_embeddings)[0][0])\n",
    "    df['intuition_similarity'] = df['document_vector'].apply(lambda vec: cosine_similarity(vec, intuition_embeddings)[0][0])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Adjust scores based on length\n",
    "def length_adjustment_bin(df, length_column='chunk_length', minimum_length=10):\n",
    "    bins = range(minimum_length, df[length_column].max()+10, 10)\n",
    "    df[f'{length_column}_bin'] = pd.cut(df[length_column], bins=bins)\n",
    "    df['evidence_mean'] = df.groupby(f'{length_column}_bin')['evidence_similarity'].transform('mean')\n",
    "    df['evidence_adj'] = df['evidence_similarity'] - df['evidence_mean']\n",
    "    df['intuition_mean'] = df.groupby(f'{length_column}_bin')['intuition_similarity'].transform('mean')\n",
    "    df['intuition_adj'] = df['intuition_similarity'] - df['intuition_mean']\n",
    "    return df\n",
    "\n",
    "# Compute evidence minus intuition score\n",
    "def evidence_minus_intuition_score(df):\n",
    "    df[['evidence_z', 'intuition_z']] = df[['evidence_adj', 'intuition_adj']].progress_apply(zscore)\n",
    "    df['evidence_minus_intuition_score'] = df['evidence_z'] - df['intuition_z']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b76cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T14:12:38.897319Z",
     "iopub.status.busy": "2024-06-23T14:12:38.896887Z",
     "iopub.status.idle": "2024-06-23T14:19:34.684212Z",
     "shell.execute_reply": "2024-06-23T14:19:34.682704Z"
    },
    "papermill": {
     "duration": 415.798602,
     "end_time": "2024-06-23T14:19:34.687140",
     "exception": false,
     "start_time": "2024-06-23T14:12:38.888538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2750722963.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"speechContent\"].replace(to_replace=r\"\\.\\.+\", value=\" \", regex=True, inplace=True)\n",
      "/tmp/ipykernel_18/2750722963.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"speechContent\"].replace(to_replace=r\"\\-\\-+\", value=\" \", regex=True, inplace=True)\n",
      "/tmp/ipykernel_18/2750722963.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"speechContent\"].replace(to_replace=r\"__+\", value=\" \", regex=True, inplace=True)\n",
      "/tmp/ipykernel_18/2750722963.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"speechContent\"].replace(to_replace=r\"\\*\\*+\", value=\" \", regex=True, inplace=True)\n",
      "/tmp/ipykernel_18/2750722963.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"speechContent\"].replace(to_replace=r\"\\s+\", value=\" \", regex=True, inplace=True)\n",
      "100%|██████████| 10784641/10784641 [01:09<00:00, 155224.38it/s]\n",
      "100%|██████████| 10784641/10784641 [00:45<00:00, 237897.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Speech length: [52.78671948376835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5391688/5391688 [00:53<00:00, 100280.46it/s]\n",
      "/tmp/ipykernel_18/2750722963.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['speechContent'] = df.speechContent.progress_apply(chunk_by_length)\n",
      "100%|██████████| 6168123/6168123 [00:36<00:00, 169272.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(df, chunk_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd1c68f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T14:19:34.931818Z",
     "iopub.status.busy": "2024-06-23T14:19:34.931424Z",
     "iopub.status.idle": "2024-06-23T16:31:27.004326Z",
     "shell.execute_reply": "2024-06-23T16:31:26.999219Z"
    },
    "papermill": {
     "duration": 7912.204046,
     "end_time": "2024-06-23T16:31:27.012750",
     "exception": false,
     "start_time": "2024-06-23T14:19:34.808704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6168123/6168123 [1:19:51<00:00, 1287.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df = compute_similarity_scores(df, model, evidence_keywords, intuition_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba9c93e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T16:31:33.495546Z",
     "iopub.status.busy": "2024-06-23T16:31:33.494669Z",
     "iopub.status.idle": "2024-06-23T16:34:44.820511Z",
     "shell.execute_reply": "2024-06-23T16:34:44.819258Z"
    },
    "papermill": {
     "duration": 194.460157,
     "end_time": "2024-06-23T16:34:44.823788",
     "exception": false,
     "start_time": "2024-06-23T16:31:30.363631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2750722963.py:78: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['evidence_mean'] = df.groupby(f'{length_column}_bin')['evidence_similarity'].transform('mean')\n",
      "/tmp/ipykernel_18/2750722963.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['intuition_mean'] = df.groupby(f'{length_column}_bin')['intuition_similarity'].transform('mean')\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adjust scores based on length\n",
    "df = length_adjustment_bin(df)\n",
    "\n",
    "# Compute evidence minus intuition score\n",
    "df = evidence_minus_intuition_score(df)\n",
    "\n",
    "df = df.drop(['document_vector'], axis=1)\n",
    "\n",
    "\n",
    "df.to_csv('speeches_all_w2v_emi.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5129324,
     "sourceId": 8577470,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5194104,
     "sourceId": 8667485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5194298,
     "sourceId": 8667738,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5264006,
     "sourceId": 8761355,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8730.793249,
   "end_time": "2024-06-23T16:34:51.669334",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-23T14:09:20.876085",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
